\documentclass{article}

% Use neurips 2024 style; for a class project, preprint (non-anonymous) is usually best.
% Options: [final], [preprint], [nonatbib]
\usepackage[preprint]{neurips_2024} % Change to [] if your instructor wants anonymous formatting.

% Recommended packages (all compatible with neurips_2024)
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % clickable references
\usepackage{url}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{subcaption}     % subfigures if needed
\usepackage{enumitem}       % better control of itemize/enumerate

% If you want natbib options (author-year, etc.), uncomment:
% \PassOptionsToPackage{numbers,sort&compress}{natbib}

% For referencing equations, figs, etc. in a consistent way
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TITLE + AUTHOR INFO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Continuous Keystroke-Based User Authentication\\
       \textit{Modeling Typing Dynamics with Hidden Markov Models}}

% Example author setup for a team project. Edit as needed.
\author{%
  Ryan Lindberg \\
  Halıcıoğlu Data Science Institute\\
  University of California, San Diego\\
  \texttt{ }
  \And
  Tanner Berman \\
  Department of Computer Science and Engineering\\
  University of California, San Diego\\
  \texttt{}
  \And
  Anthony Velikov \\
  Department of Computer Science and Engineering\\
  University of California, San Diego\\
  \texttt{avelikov@ucsd.edu}
  \And
  Audrey Meredith \\
  Halıcıoğlu Data Science Institute\\
  University of California, San Diego\\
  \texttt{}
  \And
  Preity Singh \\
  Department of Computer Science and Engineering\\
  University of California, San Diego\\
  \texttt{}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Traditional authentication methods typically verify a user only at the time of the login by checking a password once and then granting access indefinitely. In this project, we study continuous authentication based on keystroke dynamics: timing patterns and inter-key latencies that are characteristic of an individual typist. Using a public keystroke dynamics benchmark dataset, we construct sequences of keystroke timing features and model them with Hidden Markov Models. Our Hidden Markov Models aim to capture latent typing modes and temporal structure in a user's keystrokes while handling noisy, variable-length sequences. We train the models via Expectation--Maximization and evaluate whether they can distinguish authorized users from others based on the likelihood of observed keystroke sequences. Our results will explore the feasibility of keystroke based continuous authentication and more broadly illustrate how probabilistic sequence models can be applied to computer interaction data.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Description}
\label{sec:problem}

\subsection{Motivation and Problem Statement}

Conventional authentication schemes typically verify a user only at a single point in time for the login event. Once the user is authenticated, the system usually assumes that the same person remains in control of the machine. This assumption can fail in many scenarios, such as when a logged-in machine is left unattended, credentials are shared, or malware takes over a session. As a result, one off authentication does not protect against many forms of insider threat or post-login account compromise.

We address the following problem: \emph{Can we verify that the person currently using a machine is an authorized user based on their keystroke dynamics?} Specifically, we want to monitor how a user types including timing patterns, inter key latencies, and small bursts or corrections and determine whether these observed keystrokes are consistent with the typing signature of a known, authorized user.

The task can be viewed as a sequence-based verification problem:
\begin{itemize}[leftmargin=*]
    \item The input is a sequence of keystroke events, such as key-press and key-release times for a password, phrase, or longer free-text segment.
    \item The output is a decision about whether the sequence was generated by the claimed (authorized) user or by an impostor.
\end{itemize}
Rather than replacing traditional authentication, this behavioral signal is intended to \emph{complement} it by providing continuous, non-intrusive checks during a session.

This problem is important for:
\begin{itemize}[leftmargin=*]
    \item \textbf{Reducing insider risk:} Detecting anomalous typing behavior after login can help identify misuse of an already logged in account.
    \item \textbf{Detecting malicious activity:} If an attacker takes control of a session, their typing dynamics may differ from the legitimate user's.
    \item \textbf{Proctoring and monitoring:} In remote testing or secure environments, continuous behavioral checks can help confirm the intended user is present.
\end{itemize}

Our project focuses on a probabilistic modeling approach to this problem using Hidden Markov Models (HMMs), which are well-suited to temporal sequence data such as keystrokes.

\subsection{Relevance to Probabilistic Reasoning and Learning}

Keystroke dynamics are inherently sequential. When a user types, we observe a sequence of key events over time. These events exhibit patterns:
\begin{itemize}[leftmargin=*]
    \item Certain key pairs or n-grams (e.g., th, ing) tend to have characteristic timing and latency.
    \item Users often shift between different modes of typing: steady flow, fast bursts, hesitations, or error corrections.
    \item Even for the same user and phrase, timing is not deterministic; noise, fatigue, and context lead to variability.
\end{itemize}

A probabilistic model is natural here because it:
\begin{itemize}[leftmargin=*]
    \item Represents uncertainty in timing and user behavior via random variables.
    \item Allows us to model latent structure, such as unobserved typing modes or states.
    \item Provides principled ways to compute likelihoods, posterior probabilities, and decision rules 
\end{itemize}

Hidden Markov Models in particular are a good fit because:
\begin{itemize}[leftmargin=*]
    \item They model sequences $X_{1:T}$ of observations with an underlying sequence of latent states $Z_{1:T}$.
    \item The Markov structure captures how users transition between different internal states over time.
    \item HMMs handle \emph{variable-length} sequences and can work directly in the time domain via emission distributions over timing features.
    \item Standard probabilistic algorithms (forward backward, Viterbi, EM) provide efficient learning and inference for such models.
\end{itemize}

Thus, this project is directly grounded in probabilistic reasoning and learning: we specify a generative model $p(X_{1:T}, Z_{1:T})$ for keystroke sequences, learn its parameters via maximum likelihood using EM, and use probabilistic inference to perform user verification.

\subsection{Project Scope and Goals}
% - What are your concrete goals?
% - What is in scope vs. out of scope?
% - Any hypotheses you will test?
Our concrete goals are:
\begin{itemize}[leftmargin=*]
    \item \textbf{Goal 1:} Implement a data-processing pipeline that converts raw keystroke logs into discrete observation sequences suitable for Hidden Markov Models, including global quantile based discretizations and per-user sequence construction.
    \item \textbf{Goal 2:} Train one discrete HMM per user and evaluate per-repetition identification accuracy, i.e., how often we can correctly identify the user who typed a given password repetition.
    \item \textbf{Goal 3:} Explore how modeling choices (e.g., number of hidden states, number of discretizations bins, number of users) affect performance, and qualitatively interpret hidden states as user-specific typing modes.
\end{itemize}

We hypothesize that:
\begin{itemize}[leftmargin=*]
    \item A properly trained HMM will achieve substantially higher per-repetition identification accuracy than a random-guess baseline ($1 / |\mathcal{U}|$) or a simple global timing baseline that ignores temporal structure.
    \item Hidden states will correspond to interpretable typing regimes (e.g., faster vs.\ slower segments, more vs.\ less overlapping key presses).
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Sourcing and Processing}
\label{sec:data}

\subsection{Data Sources}
We use a public
\href{https://www.kaggle.com/datasets/carnegiecylab/keystroke-dynamics-benchmark-data-set}
{keystroke dynamics benchmark dataset released by Carnegie Mellon University CyLab}
available on Kaggle as the
\emph{Keystroke Dynamics Benchmark Data Set}.
In particular, we work with the \texttt{DSL-StrongPasswordData.csv} subset.

Each row in this dataset corresponds to one repetition of the same strong password (commonly reported as \texttt{.tie5Roanl}) typed by a human subject. The file contains:
\begin{itemize}[leftmargin=*]
    \item Around 50 subjects (e.g., IDs \texttt{s002}, \texttt{s018}, \dots).
    \item Up to 8 sessions per subject.
    \item Up to 50 repetitions of the password per session (roughly 400 repetitions per subject in total).
\end{itemize}

For each repetition, the dataset records:
\begin{itemize}[leftmargin=*]
    \item \textbf{Metadata:}
    \begin{itemize}[leftmargin=1.5em]
        \item \texttt{subject} (unique subject ID, e.g., \texttt{s002}).
        \item \texttt{sessionIndex} (integer: session number).
        \item \texttt{rep} (integer: repetition index within the session).
    \end{itemize}
    \item \textbf{Per-key hold times} (\texttt{H.*} columns): key down to key up durations for each key in the password and the final Return key.
    \item \textbf{Keydown--keydown latencies} (\texttt{DD.*.*} columns): elapsed time from keydown of key1 to keydown of key2.
    \item \textbf{Keyup--keydown latencies} (\texttt{UD.*.*} columns): elapsed time from keyup of key1 to keydown of key2; these values can be negative if key2 is pressed before key1 is released.
\end{itemize}



\subsection{Preprocessing and Feature Engineering}
% - Handling missing data (imputation, dropping, indicator variables).
% - Discretization / binning if you need discrete variables for BN/HMM.
% - Feature selection or dimensionality reduction.
% - Any normalization / scaling for continuous variables.
We perform the following preprocessing steps:
\begin{itemize}[leftmargin=*]
    \item \textbf{Cleaning}: No cleaning was necessary.
    \item \textbf{Encoding}: We discretized the keystroke timings into categorical bins, followed by a one hot encoding of these bins. 
    \item \textbf{Feature selection}: We used all features present in the dataset besides session and repetition indeces.
    \item \textbf{Train/validation/test splits}: We used a split ratio of 80/10/10
\end{itemize}

\subsection{Justification of Processing Choices}
% - Why are these steps important for your probabilistic model?
% - For example: discrete states required, sparsity reduction, stability of EM, etc.

These processing choices are directly driven by the requirements and assumptions of our discrete HMM. The raw keystroke data are continuous floating point timing values, but the HMM we use assumes that each observation $O_t$ is a discrete symbol drawn from a categorical distribution $P(O_t = k \mid S_t = i) = b_{ik}$. To make the data compatible with this emission model, we map each continuous timing value $x_t \in \mathbb{R}_+$ into a bin index $o_t \in {0,\dots,m-1}$ via global quantile-based binning. This produces a sequence of discrete symbols for each password repetition, which can then be modeled as emissions from the hidden typing modes $S_t$.

Finally, the one-hot encoding used in the implementation is purely a technical device to match the new \texttt{MultinomialHMM} API, which expects count vectors. This representation preserves all the information in the discretized timings while giving us a likelihood function that is well behaved for EM and exactly matches the discrete HMM formulation we use in our analysis.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modeling and Inference}
\label{sec:model}

\subsection{Probabilistic Model Specification}
% - State the type of model: BN, HMM, MDP, etc.
% - Define observed variables, latent variables, and their domains.
% - Describe the structure (graph, transition matrix, etc.).
We model the problem using a \textbf{[Bayesian Network / HMM / MDP / other]}.
Let
\begin{itemize}[leftmargin=*]
    \item $X_{1:T}$ denote the observed variables (e.g., features, emissions),
    \item $Z_{1:T}$ denote latent variables (e.g., hidden states),
    \item $Y$ denote labels / returns / decisions, if applicable.
\end{itemize}
The joint distribution factorizes as:
\begin{equation}
    p(X_{1:T}, Z_{1:T}, Y) = \dots
\end{equation}
% Fill in your concrete factorization for your chosen model.

\subsection{Model Assumptions and Dependencies}
% - List key probabilistic assumptions (conditional independence, Markov, stationarity, etc.).
% - Connect to the data: why reasonable? where might they fail?
Our Hidden Markov Model for keystroke authentication relies on the following assumptions:
\begin{itemize}[leftmargin=*]
    \item \textbf{Assumption 1 (Markov Property)}: The hidden state at time $t$ depends only on the hidden state at time $t-1$:
    $$P(S_t \mid S_{1:t-1}) = P(S_t \mid S_{t-1})$$
    \textit{Justification for keystroke data:} A user's current typing mode depends mostly on their most recent typing mode, not the entire history.
    
    \item \textbf{Assumption 2 (Conditional Independence of Observations)}: The observation at time $t$ depends only on the current hidden state:
    $$P(O_t \mid S_{1:T}, O_{1:t-1}) = P(O_t \mid S_t)$$
    \textit{Justification for keystroke data:} Given the user's current typing mode (the hidden state), the timing features 
    for the current keystroke are independent of past observations. The hidden state captures all relevant information 
    about the user's typing behavior at that moment.
    
    \item \textbf{Assumption 3 (Stationarity)}: The transition probabilities $A$ and emission probabilities $B$ remain constant throughout the sequence:
    $$P(S_t = j \mid S_{t-1} = i) = a_{ij} \text{ for all } t$$
    $$P(O_t = k \mid S_t = i) = b_{ik} \text{ for all } t$$
    \textit{Justification for keystroke data:} For a short password sequence, we assume the user's typing behavior is relatively stable. 
    For longer sequences, this assumption may need relaxation.
    
    \item \textbf{Conditional Independence Structure}: Under these assumptions, the joint distribution factorizes as:
    $$P(\mathbf{s}, \mathbf{o}) = P(S_1) \prod_{t=1}^{T-1} P(S_{t+1} \mid S_t) \prod_{t=1}^{T} P(O_t \mid S_t)$$
    $$= \pi_{s_1} \prod_{t=1}^{T-1} a_{s_t, s_{t+1}} \prod_{t=1}^{T} b_{s_t, o_t}$$
    This factorization allows for efficient inference via the forward-backward algorithm and learning via EM.

\end{itemize}

These assumptions relate to our dataset because keystroke dynamics naturally exhibit sequential structure with short-term temporal dependencies. 
The Markov assumption is reasonable for password-length sequences where typing modes change gradually. Conditional independence holds when the 
hidden state adequately captures the user's current typing behavior. The stationarity assumption may fail for very long typing sessions where 
fatigue or distraction could systematically alter transition and emission patterns, but is well-suited to our short password sequences.

\subsection{Learning / Parameter Estimation}
% - Which algorithm(s) do you use: MLE, EM, Gibbs sampling, variational inference, etc.?
% - What parameters are being learned? Give notation.
% - Describe the optimization or iterative update equations at a high level.
To estimate parameters $\theta$, we use \textbf{[Exact MLE / EM / Gibbs sampling / Policy iteration / etc.]}. 
At a high level, our learning procedure is:
\begin{enumerate}[leftmargin=*]
    \item Initialize parameters $\theta^{(0)}$ (and latent assignments if needed).
    \item For $k = 1, 2, \dots, K$:
    \begin{itemize}
        \item \textbf{E-step / Sampling / Policy evaluation}: \dots
        \item \textbf{M-step / Parameter update / Policy improvement}: \dots
    \end{itemize}
\end{enumerate}
% You can add a concise derivation or reference to a standard algorithm here.

\subsection{Inference Algorithms}
% - Describe how you perform inference at test time.
%   e.g., forward-backward, Viterbi, variable elimination, belief propagation, value iteration, etc.
% - What are you computing: marginals, MAP, expected return, etc.?
For inference on new data, we compute:
\begin{itemize}[leftmargin=*]
    \item \textbf{Predictive distribution} $p(Y \mid X_{1:T})$ using \dots
    \item \textbf{Latent state posteriors} $p(Z_t \mid X_{1:T})$ via [forward-backward / message passing / etc.].
    \item \textbf{MAP sequence} $\arg\max_{Z_{1:T}} p(Z_{1:T} \mid X_{1:T})$ via [Viterbi], if applicable.
\end{itemize}
We analyze the computational complexity of inference as \dots

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results and Discussion}
\label{sec:results}

% This section should showcase both quantitative and qualitative results,
% and discuss hyperparameters, configurations, and stability.

\subsection{Experimental Setup}
% - Describe evaluation metrics (likelihood, accuracy, F1, expected return, etc.).
% - Describe baselines or alternative configurations.
% - Mention how you chose hyperparameters.

\textbf{Dataset:} We use the CMU Keystroke Dynamics Benchmark Dataset~\cite{killourhy2009comparing}, specifically 
the \texttt{DSL-StrongPasswordData.csv} subset. Each user has around 400 repetitions of the password \texttt{.tie5Roanl}, 
which we have broken up into 80\% training, 10\% validation, and 10\% test data. This per-repetition split ensures that our 
model is evaluated on unseen typing samples, which mimics real-world authentication scenarios where new keystroke sequences must be classified.

We evaluate our model using:
\begin{itemize}[leftmargin=*]
    \item \textbf{Metrics}: We use per-repetition identification accuracy as our main evaluation metric:
    $$\text{Accuracy} = \frac{\text{\# correctly identified repetitions}}{\text{\# total test repetitions}}$$
    For a given test sequence $\mathbf{o}^{(r)}$ with true user label $u^*$, we compute:
    $$\hat{u} = \arg\max_{u \in \mathcal{U}} \log P(\mathbf{o}^{(r)} \mid \theta^{(u)})$$
    The prediction is correct if $\hat{u} = u^*$. We report overall accuracy averaged across all users. We also examine log-likelihood values 
    during training to verify model convergence.
    
    \item \textbf{Baselines / Comparisons}: We compare our HMM approach against a random guess baseline, which uniformly selects among 
    $|\mathcal{U}|$ users with expected accuracy $\frac{1}{|\mathcal{U}|}$. We also compare different HMM configurations by varying the 
    number of hidden states and discretization bins.
    
    \item \textbf{Implementation details}: We use quantile-based binning with $m = 10$ bins to convert continuous timing features into 
    discrete observation symbols, for balanced bin populations. We experiment with $n \in \{3, 5, 7, 10\}$ hidden states, 
    where each state represents a latent typing mode (e.g., fast flow, normal pace, hesitation). Training uses the EM algorithm 
    from \texttt{hmmlearn.MultinomialHMM} with maximum iterations of 20, convergence tolerance of $10^{-3}$, and fixed random seeds 
    for reproducibility. We train one separate HMM per user, which results in $|\mathcal{U}|$ independent models with parameters 
    $\theta^{(u)} = (\pi^{(u)}, A^{(u)}, B^{(u)})$. We conduct experiments with $|\mathcal{U}| \in \{2, 5, 10, 20, 30\}$ users to 
    analyze scalability. 
\end{itemize}

\subsection{Quantitative Results}
% - Tables and figures with main numbers.
% - Compare multiple configurations (hyperparameters, hidden states, structures).
% - Highlight key trends.
Table~\ref{tab:main_results} summarizes the main quantitative results.

\begin{table}[t]
    \centering
    \caption{Main quantitative results comparing different model configurations.}
    \label{tab:main_results}
    \begin{tabular}{lccc}
        \toprule
        Configuration & Metric 1 & Metric 2 & Metric 3 \\
        \midrule
        Baseline A    &  \dots   &  \dots   &  \dots   \\
        Model B       &  \dots   &  \dots   &  \dots   \\
        Model C       &  \dots   &  \dots   &  \dots   \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Qualitative Analysis}
% - What aspects of the data does the model capture or miss?
% - Do learned CPTs / state interpretations / policies align with intuition?
% - Show a few illustrative plots or sequences.
We qualitatively inspect the learned model by:
\begin{itemize}[leftmargin=*]
    \item Visualizing learned parameters (e.g., transition matrices, CPTs).
    \item Examining example sequences / trajectories and the corresponding latent states.
\end{itemize}
We observe that \dots

\subsection{Effect of Model Choices and Hyperparameters}
% - Discuss how varying hidden state count, network structure, regularization, etc. changed results.
% - Comment on stability and convergence of training.
We systematically vary \dots and observe that:
\begin{itemize}[leftmargin=*]
    \item Increasing \dots leads to \dots
    \item Overly large \dots cause \dots (overfitting/instability/etc.).
\end{itemize}

\subsection{Convergence, Scalability, and Data Requirements}
% - Did EM/Gibbs converge reliably? Any pathologies?
% - How does runtime scale with T, number of states, dataset size?
% - Would more data help? At what computational cost?
Training generally converges in \dots iterations. We find that:
\begin{itemize}[leftmargin=*]
    \item Runtime scales approximately as \dots
    \item With more data, performance \dots but training cost increases \dots
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{sec:conclusion}

% - Summarize key findings and model performance.
% - Tie back to original problem and hypotheses.
% - Briefly describe limitations and natural extensions.
In this project, we studied \dots
Our main findings are:
\begin{itemize}[leftmargin=*]
    \item \dots
    \item \dots
\end{itemize}
However, our approach is limited by \dots
Future work could explore \dots

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reflections \& Contributions}
\label{sec:reflections}

\subsection{Advice for Future Students}
% - Practical tips, pitfalls, what you wish you'd known earlier.
Students attempting similar projects may benefit from:
\begin{itemize}[leftmargin=*]
    \item Starting with a very simple baseline model to debug the pipeline.
    \item Visualizing intermediate quantities (e.g., responsibilities, posteriors) to catch bugs.
    \item Keeping careful track of data splits and random seeds.
\end{itemize}

\subsection{Team Contributions}
% - For each team member, 1–2 sentence summary of tasks and contributions.
\paragraph{Author 1.}
[1–2 sentences summarizing specific tasks and contributions.]

\paragraph{Author 2.}
[1–2 sentences summarizing specific tasks and contributions.]

\paragraph{Author 3.}
[1–2 sentences summarizing specific tasks and contributions.]

\subsection{Individual Reflections}
% - Each member writes a short reflection on what they personally learned.
\paragraph{Author 1 Reflection.}
I learned that \dots

\paragraph{Author 2 Reflection.}
I learned that \dots

\paragraph{Author 3 Reflection.}
I learned that \dots

\subsection{Use of Generative AI}
% - Brief, honest note on how Gen AI was used (if at all).
We used generative AI tools for \dots (e.g., code debugging suggestions, LaTeX formatting help),
but all modeling decisions, experiments, and final text were critically reviewed and finalized by the authors.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{References}
% NeurIPS style allows any consistent reference style. Use BibTeX if possible.
% The references section does NOT count toward the page limit. :contentReference[oaicite:1]{index=1}

\bibliographystyle{plainnat} % or another style, as long as you're consistent
\bibliography{references}    % expects a references.bib file

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Optional: Appendix (does NOT count towards main page limit)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\section{Additional Experimental Details}
\label{app:exp_details}
% - Put extended training details, extra tables/figures, and derivations here.

\section{Additional Plots and Analyses}
\label{app:plots}
% - Extra visualizations that support Section~\ref{sec:results}.

% If your instructor wants the NeurIPS-style checklist, you could
% add a section here and copy the checklist structure, but it's usually
% not necessary for a class project unless explicitly required.

\end{document}
